{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabbd34e-ddb1-4382-9082-db57582469ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = np.zeros((600,900,3), dtype=np.uint8)\n",
    "\n",
    "# sky\n",
    "# x1, x2 = 0, 300\n",
    "# y1, y2 = 0, 200\n",
    "cv.rectangle(img, (0,0), (900,500), (255,225,85),-1)\n",
    "cv.rectangle(img, (0,500), (900,600), (75,180,70), -1)\n",
    "\n",
    "# sun\n",
    "cv.circle(img, (200,150), 60, (0,255,255),-1)\n",
    "# cv.circle(img, (200,150), 75, (220,255,255),10)\n",
    "\n",
    "# tree stem\n",
    "cv.line(img, (600,500), (600, 420), (30, 65, 155), 25)\n",
    "\n",
    "# tree leaf\n",
    "# the coordinates of the vertex of the triangle\n",
    "triangle = np.array([[500, 440], [700,440], [600,75]], dtype=np.int32)\n",
    "cv.fillPoly(img, [triangle], (75,180,70))\n",
    "\n",
    "# text\n",
    "font = cv.FONT_HERSHEY_SCRIPT_COMPLEX\n",
    "cv.putText(img, \"theonlysroy\", (120,490), font, 1.5, (255,255,255),2)\n",
    "\n",
    "\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "cv.imshow(\"Image\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c0f62-2251-4d4e-9db2-a61099cce342",
   "metadata": {},
   "source": [
    "## Geometric Transformation: Translation\n",
    "\n",
    "We need to create a transformation matrix (M) and then translate any point as\n",
    "`x = x + $\\delta (x)`\n",
    "\n",
    "## Intensity Transformation\n",
    "\n",
    "It means the pixel intensity values are transformed using some **transformation functions** or __mathematical expressions__\n",
    "> s = T(r)\n",
    "\n",
    "1. Linear (_negative_ & _identity_)\n",
    "2. Logarithmic (log & inverse-log)\n",
    "3. Power law transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687fbdc5-50bb-4ff2-b8d8-a5bf48d41eb5",
   "metadata": {},
   "source": [
    "### Image Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "419e21ae-4041-4f2d-b0f9-6ede7b129fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv.imread(\"./img/BGR.png\")\n",
    "\n",
    "# 1. subtracting from 255 \n",
    "# img_neg = 255 - img\n",
    "\n",
    "# 2. bitwise not\n",
    "img_neg = cv.bitwise_not(img)\n",
    "\n",
    "# show the image\n",
    "# cv.imshow(\"Original\", img)\n",
    "# cv.imshow(\"Negative\", img_neg)\n",
    "\n",
    "out = cv.hconcat([img, img_res])\n",
    "cv.imshow(\"Result\", out)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd69c89c-c0a9-4daf-94c8-e72b43be865c",
   "metadata": {},
   "source": [
    "### Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44098c9-bb23-45de-b718-1cdaa65afc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./img/boy.jpg\")\n",
    "\n",
    "img_log = (np.log(img + 1) / (np.log(1 + np.max(img)))) * 255\n",
    "\n",
    "img_log = np.array(img_log, dtype=np.uint8)\n",
    "\n",
    "out = cv.hconcat([img, img_log])\n",
    "cv.imshow(\"log image\", img_log)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a8227f-ccd4-40b5-ad84-d13121cb800a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# transformation matrix\n",
    "M = np.array([[1,0,100], [0,1,50]], dtype=np.float32)\n",
    "\n",
    "#  read an image\n",
    "img = cv.imread(\"./img/boy.jpg\")\n",
    "rows, cols, _ = img.shape\n",
    "\n",
    "orig_coord = np.indices((cols, rows)).reshape(2,-1)\n",
    "\n",
    "# stacking the rows of 1 to form [x,y,1]\n",
    "ones_arr = np.ones(rows*cols)\n",
    "orig_coord_f = np.vstack((orig_coord, ones_arr))\n",
    "# dot product of two arrays\n",
    "transform_coord = np.dot(M, orig_coord_f)\n",
    "\n",
    "# change into int type\n",
    "transform_coord = transform_coord.astype(np.int32)\n",
    "\n",
    "# keep coordinates within image boundary\n",
    "indices = np.all((transform_coord[1] < rows, transform_coord[0] < cols, transform_coord[1] >= 0, transform_coord[0] >= 0), axis=0)\n",
    "\n",
    "# creating a zero image (black image) and projecting the points\n",
    "img1 = np.zeros_like(img)\n",
    "img1[transform_coord[1][indices], transform_coord[0][indices]] = img[orig_coord[1][indices], orig_coord[0][indices]]\n",
    "\n",
    "\n",
    "\n",
    "# show an image using matplotlib\n",
    "plt.imshow(img1, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2190f825-8020-4892-87d7-8a19e96b6856",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# translate images using openCV\n",
    "# cv2.warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]])\n",
    "# this function takes the translation matrix (M ) and translates the image\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# read an image\n",
    "img = cv.imread(\"./img/lena.jpg\")\n",
    "rows, cols, _ = img.shape\n",
    "\n",
    "# transformation matrix M\n",
    "M = np.float32([[1,0,100], [0,1,50]])\n",
    "\n",
    "# using the warpAffine() function and \n",
    "# produces the output image\n",
    "dst = cv.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "# display image using openCV\n",
    "# cv.imshow(\"Translated Image\", dst)\n",
    "\n",
    "# concatenate image\n",
    "# out = cv.hconcat([img, dst])\n",
    "# cv.imshow(\"img\", out)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f8f8f-ebc5-4849-9215-1ff69dc48292",
   "metadata": {},
   "source": [
    "## Rotation\n",
    "\n",
    "To rotate an image we need, \n",
    "- input image\n",
    "- __transformation matrix__\n",
    "- __angle of rotation__\n",
    "- __scaling factor__\n",
    "\n",
    "`x' = xcos$\\alpha - ysin$\\alpha`\n",
    "`y' = xcos$\\alpha + ysin$\\alpha`\n",
    "\n",
    "the openCV method used is ==> `getRotationMatrix2D(center, angle, scale)`\n",
    "then `warpAffine()` method used to apply the Transformation matrix on the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa8159-a17c-4e5f-8ca8-db813a7869ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# read an image\n",
    "img = cv.imread(\"./img/boy.jpg\")\n",
    "rows, cols, _ = img.shape\n",
    "\n",
    "# transformation matrix\n",
    "M = cv.getRotationMatrix2D(((cols-1)//2, (rows-1)//2),angle=90,scale=1)\n",
    "# pass it to warpAffine function\n",
    "out1 = cv.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "# using rotate method\n",
    "out2 = cv.rotate(img, cv.ROTATE_180)\n",
    "\n",
    "# display using plt\n",
    "# plt.imshow(out1)\n",
    "plt.imshow(out2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b14d5f-e291-422e-b24f-941d8436e51e",
   "metadata": {},
   "source": [
    "## Affine Transformation\n",
    "\n",
    "transforming an image without changing its collinearity, parallelism and ratio of the distance between points\n",
    "\n",
    "- rotation\n",
    "- translation\n",
    "- scaling\n",
    "- shear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "754c8d45-1275-4028-a5a3-eb095ec8f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# read an image\n",
    "img = cv.imread(\"./img/lena.jpg\")\n",
    "rows, cols = img.shape[:2]\n",
    "\n",
    "# 3 pairs of corresponding points\n",
    "new_col = 30\n",
    "new_row = 30\n",
    "\n",
    "inp_pts = np.array([[0,0], [cols-1,0], [0,rows-1]], dtype=np.float32)\n",
    "out_pts = np.array([[new_col,new_row], [(cols-1)+new_col,new_row], [new_col, (rows-1)+new_row]], dtype=np.float32)\n",
    "\n",
    "# calculate the transformation matrix M\n",
    "M = cv.getAffineTransform(inp_pts, out_pts)\n",
    "\n",
    "# apply the transformation matrix using warpAffine()\n",
    "dst = cv.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "# plt.imshow(dst)\n",
    "# plt.show()\n",
    "\n",
    "# out = cv.hconcat([img, dst])\n",
    "# cv.imshow(\"Translated\", out)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()\n",
    "\n",
    "# print(M)\n",
    "# print(rows, cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f98bc84-a121-4b5a-900e-327e6d899611",
   "metadata": {},
   "source": [
    "## Color Modesls\n",
    "### Additive\n",
    "### Subtractive\n",
    "- RGB\n",
    "- CMYK\n",
    "- HSI/HSL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c6dec4-cc11-4fc2-a781-a5302241a36d",
   "metadata": {},
   "source": [
    "## Image Enhancements\n",
    "\n",
    "### Arithmetic Operations to enhance image\n",
    "\n",
    "1. Averaging\n",
    "2. Subtraction\n",
    "3. Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b40f89-c102-4d4d-aedf-d5945f2abe1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "# Load original image\n",
    "img = cv2.imread(\"./img/butterfly.png\")\n",
    "# Create list to store noisy images\n",
    "images = []\n",
    "# Generate noisy images using cv2.randn. Can use your own mean and std.\n",
    "for _ in range(20):\n",
    "    img1 = img.copy() \n",
    "    cv2.randn(img1,(0,0,0),(50,50,50))\n",
    "    images.append(img+img1)\n",
    "# For averaging create an empty array, then add images to this array.\n",
    "img_avg=np.zeros((img.shape[0],img.shape[1],img.shape[2]),np.float32)\n",
    "for im in images:\n",
    "    img_avg=img_avg+im/20\n",
    "# Round the float values. Always specify the dtype\n",
    "img_avg=np.array(np.round(img_avg),dtype=np.uint8)\n",
    "# Display the images\n",
    "cv2.imshow('average_image',img_avg)\n",
    "cv2.imshow('original_image',img)\n",
    "cv2.imshow('noise_image',images[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6320d3fd-ccc2-44a9-a5d2-878cbbe63129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image subtraction\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv.imread(\"./img/butterfly.png\")\n",
    "img2 = cv.imread(\"./img/boy.jpg\")\n",
    "\n",
    "new_img1 = cv.resize(img1, (340,440))\n",
    "new_img2 = cv.resize(img2, (340, 440))\n",
    "\n",
    "res = cv.subtract(new_img2, new_img1)\n",
    "\n",
    "# print(img1.shape)\n",
    "# print(new_img1.shape)\n",
    "\n",
    "# cv.imshow(\"test\", new_img1)\n",
    "# cv.imshow(\"test2\", new_img2)\n",
    "cv.imshow(\"Subtracted Image\", res)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff5008-8771-4c10-9e0b-7f9c0bf6c9c9",
   "metadata": {},
   "source": [
    "## Contrast Stretching"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
